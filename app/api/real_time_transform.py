import os
import json

from fastapi import APIRouter, Depends, UploadFile, File, Form, HTTPException
from fastapi.responses import JSONResponse
from typing import Dict, List, Optional
from datetime import datetime

from requests import Session
from werkzeug.utils import secure_filename
from app.database.session import get_db
from app.model.history import History
from app.model.user import User
from app.service2.summary import generate_summary
from app.schema.realtime_schema import KeywordSearchRequest, SegmentMatch, TextMoveRequest
from app.service.auth_service import get_current_user
from app.service3.realtime_service import find_longest_staying_slide, load_or_create_result_json, save_result_json, transcribe_audio_with_timestamps

router = APIRouter()


# ì‹¤ì‹œê°„ ë³€í™˜ ê²°ê³¼ë“¤ì´ ì €ì¥ë˜ëŠ” í´ë” 
"""
file/
â””â”€â”€ 20250602_013000/               â† job_id
    â”œâ”€â”€ ê°•ì˜ìŠ¬ë¼ì´ë“œ.pdf             â† ì‚¬ìš©ìê°€ ì²˜ìŒ ì—…ë¡œë“œí•œ PDF íŒŒì¼
    â”œâ”€â”€ captioning_results.json   â† ì´ë¯¸ì§€ ìº¡ì…”ë‹ ê²°ê³¼ (ìŠ¬ë¼ì´ë“œ ë¶„ì„)
    â”œâ”€â”€ result.json               â† ìŠ¬ë¼ì´ë“œë³„ ëˆ„ì  STT ë° ìš”ì•½ ê²°ê³¼
    â””â”€â”€ 20250602_013101/          â† ì‚¬ìš©ìê°€ 1ì°¨ ì˜¤ë””ì˜¤ ì—…ë¡œë“œí•œ ì‹œê°
    â”‚   â”œâ”€â”€ audio.wav             â† ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ íŒŒì¼
    â”‚   â””â”€â”€ meta.json             â† ì²´ë¥˜ ì‹œê°„ ë“± ìŠ¬ë¼ì´ë“œ ë©”íƒ€ë°ì´í„°
    â””â”€â”€ 20250602_013150/
        â”œâ”€â”€ audio.wav             â† 2ì°¨ ì—…ë¡œë“œ ì˜¤ë””ì˜¤
        â””â”€â”€ meta.json             â† 2ì°¨ ìŠ¬ë¼ì´ë“œ ì²´ë¥˜ ë©”íƒ€ë°ì´í„°
"""
DATA_DIR = 'file'


def create_job_directory(job_id: str):
    """jobIdì— í•´ë‹¹í•˜ëŠ” ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±"""
    job_dir = os.path.join(DATA_DIR, job_id)
    audio_dir = os.path.join(job_dir, 'audio')
    os.makedirs(audio_dir, exist_ok=True)
    return job_dir, audio_dir


@router.post("/start-realtime")
async def start_realtime(doc_file: Optional[UploadFile] = File(None)):
    """
    ì‹¤ì‹œê°„ ì„¸ì…˜ ì‹œì‘ API
    PDF ìŠ¬ë¼ì´ë“œ íŒŒì¼(doc_file)ì„ file í´ë”ì— ì €ì¥í•˜ë©°, ë‚´ë¶€ì ìœ¼ë¡œ job_idë¥¼ ìƒì„±í•˜ê³  ë””ë ‰í† ë¦¬ ìƒì„±
    job_idë¥¼ ë°˜í™˜
    """
    try:
        # job_id = í˜„ì¬ ì‹œê°„ ê¸°ë°˜ ìƒì„±
        job_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        job_dir = create_job_directory(job_id)

        if doc_file:
            filename = secure_filename(doc_file.filename)
            pdf_path = os.path.join(job_dir, filename)
            with open(pdf_path, "wb") as f:
                f.write(await doc_file.read())

        return {"jobId": job_id}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))



@router.post("/realtime-process/{job_id}")
async def real_time_process(
    job_id: str,
    audio_file: Optional[UploadFile] = File(None),
    meta_json: Optional[str] = Form(None),
):
    """
    ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤/ë©”íƒ€ë°ì´í„° ì—…ë¡œë“œ API
    ì‚¬ìš©ìê°€ ìŠ¬ë¼ì´ë“œë¥¼ ë„˜ê¸°ë©° ë…¹ìŒí•œ ì˜¤ë””ì˜¤ íŒŒì¼ê³¼ í•´ë‹¹ ì‹œì  ë©”íƒ€ ì •ë³´ë¥¼ ì—…ë¡œë“œ
    ì˜¤ë””ì˜¤ë¥¼ STTë¡œ ë³€í™˜í•˜ê³  ê°€ì¥ ì˜¤ë˜ ì²´ë¥˜í•œ ìŠ¬ë¼ì´ë“œì— ëˆ„ì  ì €ì¥
    """
    try:
        # job ë””ë ‰í† ë¦¬ í™•ì¸
        job_dir = os.path.join(DATA_DIR, job_id)
        if not os.path.exists(job_dir):
            raise HTTPException(status_code=404, detail="Job ID not found")

        # í˜„ì¬ ì‹œê° ê¸°ë°˜ sub ë””ë ‰í† ë¦¬ ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        sub_dir = os.path.join(job_dir, timestamp)
        os.makedirs(sub_dir, exist_ok=True)

        audio_path = None
        meta_data = None

        # ì˜¤ë””ì˜¤ ì €ì¥
        if audio_file:
            audio_path = os.path.join(sub_dir, "audio.wav")
            with open(audio_path, "wb") as f:
                f.write(await audio_file.read())

        # ë©”íƒ€ ë°ì´í„° ì €ì¥ ë° íŒŒì‹±
        if meta_json:
            try:
                meta_data = json.loads(meta_json)
                with open(os.path.join(sub_dir, "meta.json"), 'w', encoding='utf-8') as f:
                    json.dump(meta_data, f, ensure_ascii=False, indent=2)
            except json.JSONDecodeError:
                raise HTTPException(status_code=400, detail="Invalid JSON format")

        # STT + ìŠ¬ë¼ì´ë“œ ëˆ„ì  ì²˜ë¦¬
        if audio_path and meta_data:
            longest_slide = find_longest_staying_slide(meta_data)

            if longest_slide is not None:
                stt_result = transcribe_audio_with_timestamps(audio_path)

                if stt_result and 'text' in stt_result:
                    # result.json ë¶ˆëŸ¬ì˜¤ê¸°
                    result_data = load_or_create_result_json(job_dir)

                    slide_key = f"slide{longest_slide}"
                    segment_key = f"segment{longest_slide}"

                    # ìŠ¬ë¼ì´ë“œ í•­ëª© ì´ˆê¸°í™”
                    if slide_key not in result_data:
                        result_data[slide_key] = {
                            "Concise Summary Notes": "",
                            "Bullet Point Notes": "",
                            "Keyword Notes": "",
                            "Segments": {}
                        }

                    # ì„¸ê·¸ë¨¼íŠ¸ í•­ëª© ì´ˆê¸°í™”
                    if segment_key not in result_data[slide_key]["Segments"]:
                        result_data[slide_key]["Segments"][segment_key] = {
                            "text": "",
                            "isImportant": "false",
                            "reason": "",
                            "linkedConcept": "",
                            "pageNumber": ""
                        }

                    # í…ìŠ¤íŠ¸ ëˆ„ì 
                    existing_text = result_data[slide_key]["Segments"][segment_key]["text"]
                    new_text = stt_result["text"]
                    result_data[slide_key]["Segments"][segment_key]["text"] = (
                        existing_text + " " + new_text if existing_text else new_text
                    )

                    # ë‹¤ì‹œ result.jsonì— ì €ì¥
                    save_result_json(job_dir, result_data)
                    return result_data
                


        # ì˜¤ë””ì˜¤ or ë©”íƒ€ ì—†ìŒ â†’ ê¸°ì¡´ ê²°ê³¼ë§Œ ë°˜í™˜
        return load_or_create_result_json(job_dir)

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    



@router.post("/search-keyword-locations", response_model=Dict[str, List[SegmentMatch]])
def search_segments_by_keyword(request: KeywordSearchRequest):
    """
    file/{job_id}/result.jsonì— ì €ì¥ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ
    ì‚¬ìš©ìê°€ ì…ë ¥í•œ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ìŠ¬ë¼ì´ë“œ ë° ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì°¾ì•„ ë°˜í™˜í•˜ëŠ” API
    """
    keyword = request.keyword.lower()
    job_id = request.job_id

    # result.json ê²½ë¡œ êµ¬ì„±
    result_path = os.path.join(DATA_DIR, job_id, "result.json")
    if not os.path.exists(result_path):
        raise HTTPException(status_code=404, detail="í•´ë‹¹ job_idì˜ result.json íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    # íŒŒì¼ ë¡œë“œ
    with open(result_path, "r", encoding="utf-8") as f:
        result_data = json.load(f)

    matches: List[SegmentMatch] = []

    # ìŠ¬ë¼ì´ë“œ ë° ì„¸ê·¸ë¨¼íŠ¸ íƒìƒ‰
    for slide_id, slide_data in result_data.items():
        segments = slide_data.get("Segments", {})
        for segment_id, segment_info in segments.items():
            text = segment_info.get("text", "")
            if keyword in text.lower():
                matches.append(SegmentMatch(
                    slide=slide_id,
                    segment_id=segment_id,
                    text=text
                ))

    return {"results": matches}



@router.post("/end-realtime-process/{job_id}")
async def end_real_time_process(
    job_id: str,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    ë§ˆì§€ë§‰ ìŠ¬ë¼ì´ë“œì˜ ë„˜ê¹€ ë²„íŠ¼(í˜¹ì€ 'ë³€í™˜ ë')ì„ ëˆŒë €ì„ ë•Œ í˜¸ì¶œë˜ëŠ” api
    file/{job_id}/result.json ì— ì €ì¥ëœ ìŠ¬ë¼ì´ë“œë³„ ëˆ„ì  STT ë° ìš”ì•½ ê²°ê³¼ë¥¼ History DBì— ì €ì¥
    result.jsonì˜ ê²°ê³¼ë¥¼ History DBì— ì €ì¥
    """

    job_dir = os.path.join(DATA_DIR, job_id)

    # file/{job_id} ì— ìˆëŠ” íŒŒì¼ëª… ì¶”ì¶œ 
    uploaded_pdf_filename = None
    for file in os.listdir(job_dir):
        if file.lower().endswith(".pdf"):
            uploaded_pdf_filename = file
            break

    # file/{job_id}/result.json ì†ì˜ ë‚´ìš© result_data ê°€ì ¸ì˜¤ê¸° 
    result_path = os.path.join(job_dir, "result.json")
    if not os.path.exists(result_path):
        raise FileNotFoundError("result.json íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    with open(result_path, "r", encoding="utf-8") as f:
        result_data = json.load(f)
    
    # íŒŒì¼ëª…ê³¼ result_data í™œìš©í•´ History DBì— ì €ì¥ì¥
    new_history = History(
        user_email=current_user.email,  
        filename=uploaded_pdf_filename,
        notes_json=result_data,
    )
    db.add(new_history)
    db.commit()
    db.refresh(new_history)



@router.post("/move-text-manually/{job_id}")
async def move_text_manually(job_id: str, request: TextMoveRequest):
    """
    ë¬¸ì¥ì„ í•œ ìŠ¬ë¼ì´ë“œì—ì„œ ë‹¤ë¥¸ ìŠ¬ë¼ì´ë“œë¡œ ì´ë™ì‹œí‚¨ í›„,
    ë‘ ìŠ¬ë¼ì´ë“œ ëª¨ë‘ì— ëŒ€í•´ ìš”ì•½ì„ ë‹¤ì‹œ ìƒì„±í•˜ëŠ” API.
    """
    try:
        job_dir = os.path.join(DATA_DIR, job_id)
        result_path = os.path.join(job_dir, "result.json")
        caption_path = os.path.join(job_dir, "captioning_results.json")

        if not os.path.exists(result_path) or not os.path.exists(caption_path):
            raise HTTPException(status_code=404, detail="í•„ìš”í•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

        # íŒŒì¼ ë¡œë“œ
        result_data = load_or_create_result_json(job_dir)
        with open(caption_path, "r", encoding="utf-8") as f:
            captioning_data = json.load(f)

        # 1. from_slideì—ì„œ ë¬¸ì¥ ì œê±°
        from_segments = result_data[request.from_slide]["Segments"]
        for seg in from_segments.values():
            if request.sentence in seg["text"]:
                seg["text"] = seg["text"].replace(request.sentence, "").strip()

        # 2. to_slideì— ë¬¸ì¥ ì¶”ê°€
        to_segments = result_data[request.to_slide]["Segments"]
        first_seg = next(iter(to_segments.values()))

        from_num = int(request.from_slide.replace("slide", ""))
        to_num = int(request.to_slide.replace("slide", ""))

        # ì¡°ê±´ì— ë”°ë¼ ë¬¸ì¥ ì• ë˜ëŠ” ë’¤ì— ì¶”ê°€
        if to_num > from_num:
            first_seg["text"] = request.sentence + " " + first_seg["text"]
        else:
            first_seg["text"] += " " + request.sentence
                

        # 3. ìš”ì•½ ì¬ìƒì„± ëŒ€ìƒ ìŠ¬ë¼ì´ë“œ ëª©ë¡
        affected_slides = [request.from_slide, request.to_slide]

        for slide_key in affected_slides:
            slide_number = int(slide_key.replace("slide", ""))
            slide_data = captioning_data[slide_number - 1]
            segments = result_data[slide_key]["Segments"]
            merged_text = "\n".join(seg["text"] for seg in segments.values())

            summary = generate_summary(slide_data, merged_text)

            result_data[slide_key]["Concise Summary Notes"] = f"ğŸ§ Concise Summary Notes\n{summary['concise_summary']}"
            result_data[slide_key]["Bullet Point Notes"] = f"âœ…Bullet Point Notes\n{summary['bullet_points']}"
            result_data[slide_key]["Keyword Notes"] = f"ğŸ”‘Keyword Notes\n{summary['keywords']}"
            result_data[slide_key]["Chart/Table Summary"] = f"ğŸ“ŠChart/Table Summary\n{summary['chart_summary']}"

        save_result_json(job_dir, result_data)

        return {
            "message": f"'{request.sentence}' ë¬¸ì¥ì„ {request.from_slide} â†’ {request.to_slide}ë¡œ ì´ë™í•˜ê³ , ë‘ ìŠ¬ë¼ì´ë“œ ìš”ì•½ì„ ì¬ìƒì„±í–ˆìŠµë‹ˆë‹¤.",
            "updated_slides": affected_slides
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
