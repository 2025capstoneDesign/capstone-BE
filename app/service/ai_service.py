from fastapi import Path, UploadFile
from pptx import Presentation     # python-pptx: PPT íŒŒì¼ íŒŒì‹± ë¼ì´ë¸ŒëŸ¬ë¦¬
from openai import OpenAI
from dotenv import load_dotenv

import os, uuid, shutil
import yt_dlp                     # YouTube ë™ì˜ìƒ/ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import whisper                    # OpenAI Whisper ìŒì„± ì¸ì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
import platform
import requests

import re
from typing import Tuple, Dict, List
import asyncio
from functools import partial
from pathlib import Path

# ë‹¤ìš´ë¡œë“œ ë° ì—…ë¡œë“œ íŒŒì¼ ì €ì¥ í´ë”
DOWNLOAD_DIR = "download"
os.makedirs(DOWNLOAD_DIR, exist_ok=True)

def download_youtube_audio(url: str) -> str:
    # ì €ì¥ ì˜¤ë””ì˜¤ íŒŒì¼ëª… 
    # audio_file_name = f"{uuid.uuid4().hex}.m4a"
    audio_file_name = f"{url}_audio.wav"
    output_path = os.path.join(DOWNLOAD_DIR, audio_file_name)
    # yt_dlp ì˜µì…˜ ì„¤ì •: ìµœê³  í’ˆì§ˆì˜ ì˜¤ë””ì˜¤ë§Œ ë‹¤ìš´ë¡œë“œ (m4a í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œ)
    ydl_opts = {
        'outtmpl': output_path,
        'format': 'bestaudio/best',
        # 'postprocessors': [{  # ì˜¤ë””ì˜¤ ì¶”ì¶œì„ ìœ„í•œ FFmpeg í›„ì²˜ë¦¬
        #     'key': 'FFmpegExtractAudio',
        #     'preferredcodec': 'm4a'
        # }]
    }
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        error_code = ydl.download([url])
    if error_code != 0:
        # yt_dlp ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (ì—ëŸ¬ ì½”ë“œê°€ 0ì´ ì•„ë‹ˆë©´ ì˜¤ë¥˜)
        raise Exception("YouTube ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
    return output_path

def transcribe_audio_file(audio_file: UploadFile) -> str:

    # ì—…ë¡œë“œëœ íŒŒì¼(ê°•ì˜ ë…¹ìŒë³¸)ì„ ì„œë²„ì˜ DOWNLOAD_DIRì— ì €ì¥
    file_path = os.path.join(DOWNLOAD_DIR, "audio.wav")

    with open(file_path, "wb") as buffer:
        shutil.copyfileobj(audio_file.file, buffer)
    
    # Whisper ëª¨ë¸ ë¡œë“œ ë° ìŒì„± ì¸ì‹ ìˆ˜í–‰ (small ëª¨ë¸ ì‚¬ìš©)
    print("í…ìŠ¤íŠ¸ ë³€í™˜ ì§„í–‰ì¤‘")
    model = whisper.load_model("small")
    print(file_path)
    result = model.transcribe(file_path)
    transcribed_text = result.get("text")
    print("í…ìŠ¤íŠ¸ ë³€í™˜ ì™„ë£Œ")

    # ê°•ì˜ ë…¹ìŒë³¸ì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ DOWNLOAD_DIRì— ì €ì¥
    lecture_text_path = os.path.join(DOWNLOAD_DIR, "lecture_text.txt")
    with open(lecture_text_path, "w", encoding="utf-8") as f:
        f.write(transcribed_text)
    print("ê°•ì˜ ë…¹ìŒë³¸ì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ " + lecture_text_path + "ì— ì €ì¥ ì™„ë£Œ")

    return transcribed_text

def extract_ppt_text(ppt_file: UploadFile) -> dict:
    if not ppt_file.filename.lower().endswith(".pptx"):
        raise ValueError("ì˜¬ë°”ë¥¸ PPTX íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")

    # ì—…ë¡œë“œëœ íŒŒì¼(ê°•ì˜ì•ˆ)ì„ ì„œë²„ì˜ DOWNLOAD_DIRì— ì €ì¥
    file_path = os.path.join(DOWNLOAD_DIR, ppt_file.filename)
    with open(file_path, "wb") as buffer:
        shutil.copyfileobj(ppt_file.file, buffer)

    prs = Presentation(file_path)
    
    slides_text = []

    for slide in prs.slides:
        texts = []
        for shape in slide.shapes:
            if hasattr(shape, "text"):
                text = shape.text.strip()
                if text:
                    texts.append(text)
        slide_text = "\n".join(texts)
        slides_text.append(slide_text)

    # ğŸ’¡ ìŠ¬ë¼ì´ë“œ ë²ˆí˜¸ë¥¼ í‚¤ë¡œ í•œ ë”•ì…”ë„ˆë¦¬ë¡œ ë¦¬í„´
    return {
        f"ìŠ¬ë¼ì´ë“œ {i+1}": text for i, text in enumerate(slides_text)
    }


# ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ ë¶„ì„ 
load_dotenv()

def get_libreoffice_path():
    system = platform.system()
    if system == "Windows":
        return r"C:\Program Files\LibreOffice\program\soffice.exe"
    elif system == "Darwin":
        return "/Applications/LibreOffice.app/Contents/MacOS/soffice"
    else:
        return "soffice"

client = OpenAI(
    api_key=os.getenv('OPENAI_API_KEY'),
    base_url="https://api.openai.com/v1"
)

def _analyze_image_sync(image_url):
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": """Explain slide content following these guidelines:
1. Present as a professor would during class.
2. Focus on key points, avoid unnecessary details not too long.
3. Use narrative prose.
4. Be concise yet informative."""
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": image_url,
                            "detail": "low"
                        }
                    }
                ]
            }
        ],
        max_tokens=1000
    )
    return response.choices[0].message.content

async def analyze_image(image_url):
    try:
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(
            None,  # ë””í´íŠ¸ ì“°ë ˆë“œí’€
            partial(_analyze_image_sync, image_url)
        )
        return result
    except Exception as e:
        return f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# Clova ë¬¸ë‹¨ ë‚˜ëˆ„ê¸° Apië¥¼ í™œìš©í•œ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¦¬ 
def clova_segmentation(text: str) -> list:
    CLOVA_API_URL = "https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/segmentation"
    CLOVA_API_KEY = os.getenv('CLOVA_API_KEY')

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {CLOVA_API_KEY}"
    }

    payload = {
        "text": text,
        "alpha": -100,
        "segCnt": -1,
        "postProcess": True,
        "postProcessMaxSize": 500,   #  í•œ ë¬¸ë‹¨ì˜ ìµœëŒ€ ê¸€ì ìˆ˜
        "postProcessMinSize": 300    #  í•œ ë¬¸ë‹¨ì˜ ìµœì†Œ ê¸€ì ìˆ˜
    }

    response = requests.post(CLOVA_API_URL, headers=headers, json=payload)

    if response.status_code != 200:
        raise Exception(f"CLOVA Segmentation API í˜¸ì¶œ ì‹¤íŒ¨: {response.text}")

    topic_segments = response.json()['result']['topicSeg']
    segments = [" ".join(segment) for segment in topic_segments]  # ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë¬¶ê¸°
    return segments





# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(
    api_key=os.getenv('OPENAI_API_KEY'),
    base_url="https://api.openai.com/v1"
)

# í† í° ë¹„ìš©
TOKEN_COSTS = {
    "gpt-4o": {
        "input": 2.50,
        "output": 10.00
    }
}
EXCHANGE_RATE = 1468.30

def calculate_cost(usage, model="gpt-4o"):
    input_cost = (usage.prompt_tokens / 1_000_000) * TOKEN_COSTS[model]["input"]
    output_cost = (usage.completion_tokens / 1_000_000) * TOKEN_COSTS[model]["output"]
    return (input_cost + output_cost) * EXCHANGE_RATE

def parse_note_sections(note_text: str) -> Dict[str, str]:
    """GPT ì¶œë ¥ ê²°ê³¼ë¥¼ ì„¹ì…˜ë³„ë¡œ íŒŒì‹±."""
    sections = {
        "Concise Summary Notes": "",
        "Bullet Point Notes": "",
        "Keyword Notes": "",
        "Chart/Table Summary": ""
    }

    # ì •ê·œí‘œí˜„ì‹ íŒ¨í„´
    patterns = {
        "Concise Summary Notes": r"1\. Concise Summary Notes",
        "Bullet Point Notes": r"2\. Bullet Point Notes",
        "Keyword Notes": r"3\. Keyword Notes",
        "Chart/Table Summary": r"4\. Chart/Table Summary"
    }

    matches = {}
    for key, pattern in patterns.items():
        match = re.search(pattern, note_text)
        if match:
            matches[key] = match.start()

    # ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    sorted_keys = sorted(matches, key=lambda k: matches[k])

    for i, key in enumerate(sorted_keys):
        start = matches[key]
        end = matches[sorted_keys[i+1]] if i+1 < len(sorted_keys) else len(note_text)
        content = note_text[start:end].strip()
        sections[key] = content

    return sections

def generate_note(slide_caption: str, matched_segments: List[str]) -> Tuple[Dict[str, str], float]:
    """ìŠ¬ë¼ì´ë“œ ìº¡ì…˜ + ë§¤ì¹­ëœ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ GPTë¡œ í•„ê¸° ìƒì„±í•˜ê³  íŒŒì‹±."""
    merged_segments = "\n".join(matched_segments)

    prompt = f"""
You are an expert in creating structured notes based on long user inputs.

The user's input consists of:
- A **slide image caption** that summarizes the slide's main content, and
- A set of **matching lecture segments** explaining details related to that slide.

Slide Image Caption:
\"\"\"
{slide_caption}
\"\"\"

Matched Lecture Segments:
\"\"\"
{merged_segments}
\"\"\"

# Important Writing Rules:

**ABSOLUTELY MUST** use the exact following titles, numbered exactly as shown:
   - "1. Concise Summary Notes"
   - "2. Bullet Point Notes"
   - "3. Keyword Notes"
   - "4. Chart/Table Summary"

1. **Concise Summary Notes**  
- Summarize the combined content into natural sentences within 7â€“8 lines.

2. **Bullet Point Notes**  
- List the key points clearly and briefly in bullet points.  
- Each point should be one sentence or a short phrase.

3. **Keyword Notes**  
- Extract and list around 10 major keywords, concepts, or important terms.  
- Provide a brief explanation for each keyword.

4. **Chart/Table Summary**  
- Try your best to summarize the content in a **chart or table format** if possible.
- A table is especially helpful when listing concepts, comparing items, or explaining step-by-step processes.  
- Only write "Omitted" if it is clearly impossible to express the content in a structured chart or table.

Important writing guidelines you must follow:
- Respond in English if the user input is in English; respond in Korean if the input is in Korean.
- Make the notes concise and clear so that users can understand quickly.
- Eliminate redundant expressions and maintain a logical flow.
- Clearly separate each style of note-taking in the output.
- If a style is not applicable, do not leave it blank; explicitly write Omitted.
- If there are no matching lecture segments for a slide, generate the notes based as much as possible on the slide's image caption alone.
- Each style must be written only once. Do not repeat or duplicate the same style multiple times.

# Output Format Example:

1. Concise Summary Notes
(Your concise summary here)

2. Bullet Point Notes
(Your bullet points here)

3. Keyword Notes
(Your keywords here)

4. Chart/Table Summary
(Your table here or "Omitted")

Now, generate the notes accordingly.
"""
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are a helpful AI assistant specialized in creating structured lecture notes."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1500,
            temperature=0.3,
        )

        note_text = response.choices[0].message.content.strip()

        print("GPT ì‘ë‹µ ì›ë³¸:\n", note_text)

        note_sections = parse_note_sections(note_text)
        cost = calculate_cost(response.usage)

        return note_sections, cost

    except Exception as e:
        return {"error": f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}, 0.0

