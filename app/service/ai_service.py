from fastapi import UploadFile
from pptx import Presentation     # python-pptx: PPT íŒŒì¼ íŒŒì‹± ë¼ì´ë¸ŒëŸ¬ë¦¬
from openai import OpenAI
from dotenv import load_dotenv

import os, uuid, shutil
import yt_dlp                     # YouTube ë™ì˜ìƒ/ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import whisper                    # OpenAI Whisper ìŒì„± ì¸ì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
import platform
import requests

import asyncio
from functools import partial

# ë‹¤ìš´ë¡œë“œ ë° ì—…ë¡œë“œ íŒŒì¼ ì €ì¥ í´ë”
DOWNLOAD_DIR = "download"
os.makedirs(DOWNLOAD_DIR, exist_ok=True)

def download_youtube_audio(url: str) -> str:
    # ì €ì¥ ì˜¤ë””ì˜¤ íŒŒì¼ëª… 
    # audio_file_name = f"{uuid.uuid4().hex}.m4a"
    audio_file_name = f"{url}_audio.wav"
    output_path = os.path.join(DOWNLOAD_DIR, audio_file_name)
    # yt_dlp ì˜µì…˜ ì„¤ì •: ìµœê³  í’ˆì§ˆì˜ ì˜¤ë””ì˜¤ë§Œ ë‹¤ìš´ë¡œë“œ (m4a í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œ)
    ydl_opts = {
        'outtmpl': output_path,
        'format': 'bestaudio/best',
        # 'postprocessors': [{  # ì˜¤ë””ì˜¤ ì¶”ì¶œì„ ìœ„í•œ FFmpeg í›„ì²˜ë¦¬
        #     'key': 'FFmpegExtractAudio',
        #     'preferredcodec': 'm4a'
        # }]
    }
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        error_code = ydl.download([url])
    if error_code != 0:
        # yt_dlp ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (ì—ëŸ¬ ì½”ë“œê°€ 0ì´ ì•„ë‹ˆë©´ ì˜¤ë¥˜)
        raise Exception("YouTube ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
    return output_path

def transcribe_audio_file(audio_file: UploadFile) -> str:
    # ì—…ë¡œë“œëœ íŒŒì¼(ê°•ì˜ ë…¹ìŒë³¸)ì„ ì„œë²„ì˜ DOWNLOAD_DIRì— ì €ì¥
    file_path = os.path.join(DOWNLOAD_DIR, audio_file.filename)
    with open(file_path, "wb") as buffer:
        shutil.copyfileobj(audio_file.file, buffer)

    # Whisper ëª¨ë¸ ë¡œë“œ ë° ìŒì„± ì¸ì‹ ìˆ˜í–‰ (small ëª¨ë¸ ì‚¬ìš©)
    print("í…ìŠ¤íŠ¸ ë³€í™˜ ì§„í–‰ì¤‘")
    model = whisper.load_model("small")
    result = model.transcribe(file_path)
    transcribed_text = result.get("text")
    print("í…ìŠ¤íŠ¸ ë³€í™˜ ì™„ë£Œ")

    # ê°•ì˜ ë…¹ìŒë³¸ì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ DOWNLOAD_DIRì— ì €ì¥
    lecture_text_path = os.path.join(DOWNLOAD_DIR, "lecture_text.txt")
    with open(lecture_text_path, "w", encoding="utf-8") as f:
        f.write(transcribed_text)
    print("ê°•ì˜ ë…¹ìŒë³¸ì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ " + lecture_text_path + "ì— ì €ì¥ ì™„ë£Œ")

    return transcribed_text

def extract_ppt_text(ppt_file: UploadFile) -> dict:
    if not ppt_file.filename.lower().endswith(".pptx"):
        raise ValueError("ì˜¬ë°”ë¥¸ PPTX íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")

    # ì—…ë¡œë“œëœ íŒŒì¼(ê°•ì˜ì•ˆ)ì„ ì„œë²„ì˜ DOWNLOAD_DIRì— ì €ì¥
    file_path = os.path.join(DOWNLOAD_DIR, ppt_file.filename)
    with open(file_path, "wb") as buffer:
        shutil.copyfileobj(ppt_file.file, buffer)

    prs = Presentation(file_path)
    
    slides_text = []

    for slide in prs.slides:
        texts = []
        for shape in slide.shapes:
            if hasattr(shape, "text"):
                text = shape.text.strip()
                if text:
                    texts.append(text)
        slide_text = "\n".join(texts)
        slides_text.append(slide_text)

    # ğŸ’¡ ìŠ¬ë¼ì´ë“œ ë²ˆí˜¸ë¥¼ í‚¤ë¡œ í•œ ë”•ì…”ë„ˆë¦¬ë¡œ ë¦¬í„´
    return {
        f"ìŠ¬ë¼ì´ë“œ {i+1}": text for i, text in enumerate(slides_text)
    }


# ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ ë¶„ì„ 
load_dotenv()

def get_libreoffice_path():
    system = platform.system()
    if system == "Windows":
        return r"C:\Program Files\LibreOffice\program\soffice.exe"
    elif system == "Darwin":
        return "/Applications/LibreOffice.app/Contents/MacOS/soffice"
    else:
        return "soffice"

client = OpenAI(
    api_key=os.getenv('OPENAI_API_KEY'),
    base_url="https://api.openai.com/v1"
)

def _analyze_image_sync(image_url):
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": """Explain slide content following these guidelines:
1. Present as a professor would during class.
2. Focus on key points, avoid unnecessary details not too long.
3. Use narrative prose.
4. Be concise yet informative."""
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": image_url,
                            "detail": "low"
                        }
                    }
                ]
            }
        ],
        max_tokens=1000
    )
    return response.choices[0].message.content

async def analyze_image(image_url):
    try:
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(
            None,  # ë””í´íŠ¸ ì“°ë ˆë“œí’€
            partial(_analyze_image_sync, image_url)
        )
        return result
    except Exception as e:
        return f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# Clova ë¬¸ë‹¨ ë‚˜ëˆ„ê¸° Apië¥¼ í™œìš©í•œ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¦¬ 
def clova_segmentation(text: str) -> list:
    CLOVA_API_URL = "https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/segmentation"
    CLOVA_API_KEY = os.getenv('CLOVA_API_KEY')

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {CLOVA_API_KEY}"
    }

    payload = {
        "text": text,
        "alpha": -100,
        "segCnt": -1,
        "postProcess": True,
        "postProcessMaxSize": 500,   #  í•œ ë¬¸ë‹¨ì˜ ìµœëŒ€ ê¸€ì ìˆ˜
        "postProcessMinSize": 300    #  í•œ ë¬¸ë‹¨ì˜ ìµœì†Œ ê¸€ì ìˆ˜
    }

    response = requests.post(CLOVA_API_URL, headers=headers, json=payload)

    if response.status_code != 200:
        raise Exception(f"CLOVA Segmentation API í˜¸ì¶œ ì‹¤íŒ¨: {response.text}")

    topic_segments = response.json()['result']['topicSeg']
    segments = [" ".join(segment) for segment in topic_segments]  # ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë¬¶ê¸°
    return segments