import subprocess
from fastapi import APIRouter, Depends, File, UploadFile
from fastapi.responses import JSONResponse

from app.model.history import History
from app.service.ai_service import clova_segmentation, download_youtube_audio_segment, generate_note, get_libreoffice_path, analyze_image, analyze_image_kor, process_important_segments, transcribe_audio_file, extract_ppt_text  # ì„œë¹„ìŠ¤ ëª¨ë“ˆ ì„í¬íŠ¸
from app.service.mapping_service import LectureSlideMapper, LectureSlideMapperKor
from app.service.auth_service import get_current_user

from app.schema.ai_schema import PptExtractResponse, YouTubeURLRequest, AudioTranscibeResponse
from app.schema.mapping_schema import LectureTextRequest, MappingResultResponse
from app.schema.history_schema import HistoryResponse

from app.model.user import User
from requests import Session
from app.database.session import get_db

from collections import OrderedDict
from pptx import Presentation
from pdf2image import convert_from_path
from fastapi import Form
import tempfile
import os
import shutil
import base64
import io
import logging

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

router = APIRouter()

@router.post("/extract-youtube-audio")
async def youtube_audio(request: YouTubeURLRequest):
    """
    YouTube ì˜ìƒì—ì„œ ì „ì²´ ë˜ëŠ” íŠ¹ì • êµ¬ê°„ì˜ ì˜¤ë””ì˜¤ë¥¼ ì¶”ì¶œ
    """
    try:
        if request.start_time and request.end_time:
            # â±ï¸ íŠ¹ì • êµ¬ê°„ ì˜ë¼ë‚´ê¸°
            from datetime import datetime

            fmt = "%H:%M:%S"
            start = datetime.strptime(request.start_time, fmt)
            end = datetime.strptime(request.end_time, fmt)
            duration_sec = (end - start).total_seconds()
            if duration_sec <= 0:
                raise ValueError("end_timeì€ start_timeë³´ë‹¤ ë’¤ì—¬ì•¼ í•©ë‹ˆë‹¤.")

            # ì´ˆ ë‹¨ìœ„ â†’ HH:MM:SS í¬ë§·
            hours = int(duration_sec // 3600)
            minutes = int((duration_sec % 3600) // 60)
            seconds = int(duration_sec % 60)
            duration_str = f"{hours:02}:{minutes:02}:{seconds:02}"

            file_path = download_youtube_audio_segment(
                url=request.youtube_url,
                start_time=request.start_time,
                duration=duration_str
            )
        else:
            # ğŸ¬ ì „ì²´ ì˜ìƒì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ
            from app.service.ai_service import download_youtube_audio
            file_path = download_youtube_audio(request.youtube_url)

        return {"message": "YouTube ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ", "data": file_path}
    
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"message": f"ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨: {e}", "data": None}
        )


@router.post("/transcribe-audio", response_model=AudioTranscibeResponse)
async def transcribe_audio(audio_file: UploadFile = File(...)):
    """
    ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ íŒŒì¼ì„ Whisper ëª¨ë¸ë¡œ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    """
    try:
        transcribed_text = transcribe_audio_file(audio_file)
        return {"message": "ì˜¤ë””ì˜¤ í…ìŠ¤íŠ¸ ë³€í™˜ ì„±ê³µ", "data": transcribed_text}
    except Exception as e:
        return JSONResponse(status_code=500, content={"message": f"ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {e}", "data": None})
    

@router.post("/extract-ppt-text", response_model=PptExtractResponse)
def extract_ppt_text_endpoint(ppt_file: UploadFile = File(...)):
    """
    ì—…ë¡œë“œëœ PPTX íŒŒì¼ì—ì„œ ìŠ¬ë¼ì´ë“œë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ 
    """
    try:
        text_list = extract_ppt_text(ppt_file)
        return {"message": "PPT í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ", "data": text_list}
    except ValueError as e:
        # ì˜ëª»ëœ ì…ë ¥ ë“±ìœ¼ë¡œ ì¸í•œ ì‚¬ìš©ì ì˜¤ë¥˜
        return JSONResponse(status_code=400, content={"message": str(e), "data": None})
    except Exception as e:
        return JSONResponse(status_code=500, content={"message": f"PPT ì²˜ë¦¬ ì‹¤íŒ¨: {e}", "data": None})


mapper = LectureSlideMapper()
@router.post("/text-slide-mapping")
def map_lecture_to_slide(request: LectureTextRequest):
    """
    ê°•ì˜ í…ìŠ¤íŠ¸ + ìŠ¬ë¼ì´ë“œ í…ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ë§¤í•‘ í›„ ìŠ¬ë¼ì´ë“œë³„ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸ë¡œ ê·¸ë£¹í™”
    (segment_index, text, similarity_score ëª¨ë‘ í¬í•¨)
    """

    # ì´ë¯¸ì§€ ìº¡ì…”ë‹ ê²°ê³¼ë¥¼ ìŠ¬ë¼ì´ë“œ í…ìŠ¤íŠ¸ë¡œ slide_texts

    # ê°•ì˜ í…ìŠ¤íŠ¸ë¥¼ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë¶„ë¦¬ (í•˜ë‚˜ì˜ ì„¸ê·¸ë¨¼íŠ¸ì— 10ë¬¸ì¥ ê³ ì •)
    segments = mapper.preprocess_and_split_text(request.lecture_text)

    results = mapper.map_lecture_text_to_slides(
        segment_texts=segments, 
        slide_texts=request.slide_texts
    )

    print("ê°•ì˜ ë…¹ìŒë³¸ì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¦¬ ì™„ë£Œ")

    # 2. ìŠ¬ë¼ì´ë“œë³„ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸ë¡œ ë¬¶ê¸°
    slide_to_segments = {}

    for res in results:
        segment_idx = res["segment_index"]     
        slide_idx = res["matched_slide_index"]  
        similarity_score = res["similarity_score"] 
        slide_key = f"slide{slide_idx}"

        if slide_key not in slide_to_segments:
            slide_to_segments[slide_key] = []

        # ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€
        slide_to_segments[slide_key].append({
            "segment_index": segment_idx,
            "text": segments[segment_idx],
            "similarity_score": round(similarity_score, 4)  # ì†Œìˆ˜ì  4ìë¦¬ë¡œ ê¹”ë”í•˜ê²Œ
        })

    print("ìŠ¬ë¼ì´ë“œë³„ ì„¸ê·¸ë¨¼íŠ¸ ë§¤ì¹­ ì™„ë£Œ")

    # 3. ìµœì¢… ê²°ê³¼ ë°˜í™˜
    return JSONResponse(content=slide_to_segments)

#################################
mapper_kor = LectureSlideMapperKor()
@router.post("/text-slide-mapping-kor")
def map_lecture_to_slide_kor(request: LectureTextRequest):
    """
    (í•œêµ­ì–´ìš©) ê°•ì˜ í…ìŠ¤íŠ¸ + ìŠ¬ë¼ì´ë“œ í…ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ë§¤í•‘ í›„,
    ìŠ¬ë¼ì´ë“œë³„ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸ë¡œ ê·¸ë£¹í™” (segment_index, text, similarity_score í¬í•¨)
    """

    # 1. ê°•ì˜ í…ìŠ¤íŠ¸ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¦¬
    segments = mapper_kor.preprocess_and_split_text_kor(request.lecture_text, 7)

    # 2. ê° ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ê°€ì¥ ìœ ì‚¬í•œ ìŠ¬ë¼ì´ë“œì— ë§¤í•‘
    results = mapper_kor.map_lecture_text_to_slides_kor(
        segment_texts=segments,
        slide_texts=request.slide_texts
    )

    print("ğŸ‡°ğŸ‡· í•œê¸€ ê°•ì˜ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¦¬ ë° ë§¤í•‘ ì™„ë£Œ")

    # 3. ìŠ¬ë¼ì´ë“œë³„ë¡œ ì„¸ê·¸ë¨¼íŠ¸ ë¬¶ê¸°
    slide_to_segments = {}
    for res in results:
        segment_idx = res["segment_index"]
        slide_idx = res["matched_slide_index"]
        similarity_score = res["similarity_score"]
        slide_key = f"slide{slide_idx}"

        if slide_key not in slide_to_segments:
            slide_to_segments[slide_key] = []

        slide_to_segments[slide_key].append({
            "segment_index": segment_idx,
            "text": segments[segment_idx],
            "similarity_score": round(similarity_score, 4)
        })

    print("ğŸ‡°ğŸ‡· ìŠ¬ë¼ì´ë“œë³„ ë§¤ì¹­ ê²°ê³¼ ì™„ë£Œ")
    return JSONResponse(content=slide_to_segments)




@router.post("/image-captioning")
async def image_captioning(file: UploadFile = File(...)):
    """
    PPT or PDF -> PDF -> Image -> ìŠ¬ë¼ì´ë“œë³„ ì„¤ëª… ì¶œë ¥ 
    """
    try:
        temp_dir = tempfile.mkdtemp()
        uploaded_path = os.path.join(temp_dir, file.filename)

        # 1. íŒŒì¼ ì €ì¥
        with open(uploaded_path, "wb") as f:
            shutil.copyfileobj(file.file, f)

        print("íŒŒì¼ ì €ì¥ ì™„ë£Œ")

        file_ext = os.path.splitext(file.filename)[-1].lower()

        # 2. ìŠ¬ë¼ì´ë“œ ìˆ˜ í™•ì¸ (PPTXì¼ ë•Œë§Œ)
        if file_ext == ".pptx":
            prs = Presentation(uploaded_path)
            total_slides = len(prs.slides)
        else:
            total_slides = None  # PDFëŠ” ìŠ¬ë¼ì´ë“œ ìˆ˜ë¥¼ ì¶”ì •í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ None

        # 3. PDF ê²½ë¡œ ê²°ì •
        if file_ext == ".pptx":
            # PPTX -> PDF ë³€í™˜
            subprocess.run(
                [LIBREOFFICE_PATH, "--headless", "--convert-to", "pdf", "--outdir", temp_dir, uploaded_path],
                check=True
            )
            pdf_path = os.path.join(temp_dir, os.path.splitext(file.filename)[0] + ".pdf")
            if not os.path.exists(pdf_path):
                raise Exception("PDF ë³€í™˜ ì‹¤íŒ¨")
        elif file_ext == ".pdf":
            pdf_path = uploaded_path
        else:
            raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. PDF ë˜ëŠ” PPTXë§Œ í—ˆìš©ë©ë‹ˆë‹¤.")

        print("PDF ì¤€ë¹„ ì™„ë£Œ")

        # 4. PDF -> ì´ë¯¸ì§€ ë³€í™˜
        images = convert_from_path(
            pdf_path,
            poppler_path=os.getenv('POPPLER_PATH')
        )
        if not images:
            raise Exception("PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

        print("PDF -> ì´ë¯¸ì§€ ë³€í™˜ ì™„ë£Œ")

        print("ì´ë¯¸ì§€ ìº¡ì…”ë‹ ì‹œì‘")

        results = {}
        if total_slides:
            results["total_slide"] = total_slides

        # 5. ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ ìº¡ì…”ë‹
        for idx, img in enumerate(images, start=1):
            buffered = io.BytesIO()
            img.save(buffered, format="JPEG")
            img_base64 = base64.b64encode(buffered.getvalue()).decode()
            image_url = f"data:image/jpeg;base64,{img_base64}"

            caption = await analyze_image(image_url)
            results[f"slide{idx}"] = caption

        print("ì´ë¯¸ì§€ ìº¡ì…”ë‹ ì™„ë£Œ")
        shutil.rmtree(temp_dir)

        return JSONResponse(content=results)

    except Exception as e:
        logger.debug(e, stack_info=True)
        if 'temp_dir' in locals() and os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
        return JSONResponse(status_code=500, content={"message": f"ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"})
    
#############################################

@router.post("/image-captioning-kor")
async def image_captioning(file: UploadFile = File(...)):
    """
    PPT or PDF -> PDF -> Image -> ìŠ¬ë¼ì´ë“œë³„ ì„¤ëª… ì¶œë ¥ 
    """
    try:
        temp_dir = tempfile.mkdtemp()
        uploaded_path = os.path.join(temp_dir, file.filename)

        # 1. íŒŒì¼ ì €ì¥
        with open(uploaded_path, "wb") as f:
            shutil.copyfileobj(file.file, f)

        print("íŒŒì¼ ì €ì¥ ì™„ë£Œ")

        file_ext = os.path.splitext(file.filename)[-1].lower()

        # 2. ìŠ¬ë¼ì´ë“œ ìˆ˜ í™•ì¸ (PPTXì¼ ë•Œë§Œ)
        if file_ext == ".pptx":
            prs = Presentation(uploaded_path)
            total_slides = len(prs.slides)
        else:
            total_slides = None  # PDFëŠ” ìŠ¬ë¼ì´ë“œ ìˆ˜ë¥¼ ì¶”ì •í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ None

        # 3. PDF ê²½ë¡œ ê²°ì •
        if file_ext == ".pptx":
            # PPTX -> PDF ë³€í™˜
            subprocess.run(
                [LIBREOFFICE_PATH, "--headless", "--convert-to", "pdf", "--outdir", temp_dir, uploaded_path],
                check=True
            )
            pdf_path = os.path.join(temp_dir, os.path.splitext(file.filename)[0] + ".pdf")
            if not os.path.exists(pdf_path):
                raise Exception("PDF ë³€í™˜ ì‹¤íŒ¨")
        elif file_ext == ".pdf":
            pdf_path = uploaded_path
        else:
            raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. PDF ë˜ëŠ” PPTXë§Œ í—ˆìš©ë©ë‹ˆë‹¤.")

        print("PDF ì¤€ë¹„ ì™„ë£Œ")

        # 4. PDF -> ì´ë¯¸ì§€ ë³€í™˜
        images = convert_from_path(
            pdf_path,
            poppler_path=os.getenv('POPPLER_PATH')
        )
        if not images:
            raise Exception("PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

        print("PDF -> ì´ë¯¸ì§€ ë³€í™˜ ì™„ë£Œ")

        print("ì´ë¯¸ì§€ ìº¡ì…”ë‹ ì‹œì‘")

        results = {}
        if total_slides:
            results["total_slide"] = total_slides

        # 5. ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ ìº¡ì…”ë‹
        for idx, img in enumerate(images, start=1):
            buffered = io.BytesIO()
            img.save(buffered, format="JPEG")
            img_base64 = base64.b64encode(buffered.getvalue()).decode()
            image_url = f"data:image/jpeg;base64,{img_base64}"

            caption = await analyze_image_kor(image_url)
            results[f"slide{idx}"] = caption

        print("ì´ë¯¸ì§€ ìº¡ì…”ë‹ ì™„ë£Œ")
        shutil.rmtree(temp_dir)

        return JSONResponse(content=results)

    except Exception as e:
        logger.debug(e, stack_info=True)
        if 'temp_dir' in locals() and os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
        return JSONResponse(status_code=500, content={"message": f"ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"})
    



mapper = LectureSlideMapper()
LIBREOFFICE_PATH = get_libreoffice_path()
@router.post("/process-lecture")
async def process_lecture(
    audio_file: UploadFile = File(...),
    doc_file: UploadFile = File(...),
    skip_transcription: bool = Form(False),
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    ê°•ì˜ ë…¹ìŒë³¸ + PPT íŒŒì¼ ì…ë ¥ë°›ì•„ì„œ ìŠ¬ë¼ì´ë“œë³„ ì„¸ê·¸ë¨¼íŠ¸ ë§¤ì¹­ ê²°ê³¼ ë°˜í™˜í™˜
    """

    try:
        doc_contents = await doc_file.read()

        ## ê°•ì˜ì•ˆ download í´ë”ì— ë‹¤ìš´ë¡œë“œ
        download_path = os.path.join(("download"), doc_file.filename)
        with open(download_path, "wb") as f:
            f.write(doc_contents)


        ### 1. ì˜¤ë””ì˜¤ íŒŒì¼ í…ìŠ¤íŠ¸ ë³€í™˜ (ë˜ëŠ” ìŠ¤í‚µ)
        if skip_transcription:
            with open(os.path.join("download", "lecture_text.txt"), "r", encoding="utf-8") as f:
                lecture_text = f.read()
        else:
            lecture_text = transcribe_audio_file(audio_file) 
        
        print("ì˜¤ë””ì˜¤ í…ìŠ¤íŠ¸ ë³€í™˜ ì™„ë£Œ")

        # 2. PPT íŒŒì¼ ì €ì¥ ë° ë³€í™˜
        temp_dir = tempfile.mkdtemp()
        file_path = os.path.join(temp_dir, doc_file.filename)

        with open(file_path , "wb") as f:
            f.write(doc_contents)

        file_ext = os.path.splitext(doc_file.filename)[-1].lower()

        # PPT/PDF ì²˜ë¦¬ 
        if file_ext == ".pptx":
            # LibreOfficeë¥¼ ì‚¬ìš©í•˜ì—¬ PDFë¡œ ë³€í™˜
            subprocess.run([LIBREOFFICE_PATH, "--headless", "--convert-to", "pdf", "--outdir", temp_dir, file_path], check=True)
            file_path = os.path.join(temp_dir, os.path.splitext(doc_file.filename)[0] + ".pdf")

            if not os.path.exists(file_path):
                raise Exception("PDF ë³€í™˜ ì‹¤íŒ¨")

        elif file_ext != ".pdf":
            raise ValueError("ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. PPTX ë˜ëŠ” PDFë§Œ í—ˆìš©ë©ë‹ˆë‹¤.")
        
        images = convert_from_path(
            file_path ,
            poppler_path=os.getenv('POPPLER_PATH')
        )
        print(f"PDFì—ì„œ ë³€í™˜ëœ ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ ìˆ˜: {len(images)}")

        print("ì´ë¯¸ì§€ ìº¡ì…”ë‹ ì‹œì‘")

        ### 3. ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ë³„ ìº¡ì…˜ ì¶”ì¶œ
        slide_captions = []
        for img in images:
            buffered = io.BytesIO()
            img.save(buffered, format="JPEG")
            img_base64 = base64.b64encode(buffered.getvalue()).decode()
            image_url = f"data:image/jpeg;base64,{img_base64}"

            caption = await analyze_image(image_url)
            slide_captions.append(caption)

        print(f"ì´ë¯¸ì§€ ìº¡ì…”ë‹ ê²°ê³¼: {slide_captions}")

        
        print("ì´ë¯¸ì§€ ìº¡ì…”ë‹ ì™„ë£Œ")

        # 4. CLOVA Segmentation ì‚¬ìš©í•´ì„œ ê°•ì˜ ë…¹ìŒë³¸ì„ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë‚˜ëˆ„ê¸° / ê³ ì •ëœ ê°œìˆ˜ì˜ ë¬¸ì¥ìœ¼ë¡œ ì´ë£¨ì–´ì§„ ì„¸ê·¸ë¨¼íŠ¸ ì‚¬ìš©
        # segments = clova_segmentation(lecture_text)
        segments = mapper.preprocess_and_split_text(lecture_text) 

        print("Clova API í™œìš© ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¦¬ ì™„ë£Œ")

        # 5. ì„¸ê·¸ë¨¼íŠ¸-ìŠ¬ë¼ì´ë“œ ë§¤í•‘
        results = mapper.map_lecture_text_to_slides(
            segment_texts=segments,
            slide_texts=slide_captions
        )

        print("ì„¸ê·¸ë¨¼íŠ¸ ìŠ¬ë¼ì´ë“œ ë§¤í•‘ ì™„ë£Œ")

        # ì¤‘ìš” ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ 
        raw_json = {f"segment{i}": seg for i, seg in enumerate(segments)}
        important_segments_result = process_important_segments(raw_json)

        print("ë§¤í•‘ ê²°ê³¼ ìŠ¬ë¼ì´ë“œ ë³„ë¡œ ë¬¶ê¸°")

        # 6. ë§¤í•‘ ê²°ê³¼ë¥¼ ìŠ¬ë¼ì´ë“œë³„ë¡œ ë¬¶ê¸°
        slide_to_segments = {}
        for slide_idx in range(len(slide_captions)):
            slide_key = f"slide{slide_idx + 1}"
            slide_to_segments[slide_key] = []

        for res in results:
            segment_idx = res["segment_index"]
            slide_idx = res["matched_slide_index"]
            similarity_score = res["similarity_score"]
            slide_key = f"slide{slide_idx+1}"

            seg_id = f"segment{segment_idx}"
            is_important = seg_id in important_segments_result

            slide_to_segments[slide_key].append({
                "segment_key": seg_id,
                "text": segments[segment_idx],
                "isImportant": str(is_important).lower(),
                "reason": important_segments_result.get(seg_id, {}).get("reason", ""),
                "linkedConcept": "",
                "pageNumber": ""
            })

        sorted_slide_to_segments = OrderedDict(sorted(slide_to_segments.items(), key=lambda x: int(x[0].replace("slide", ""))))

        print("ê° ìŠ¬ë¼ì´ë“œë³„ í•„ê¸° ìƒì„± ì‹œì‘")

        final_notes = {}
        for slide_key, segment_list in sorted_slide_to_segments.items():
            slide_idx = int(slide_key.replace("slide", "")) - 1
            slide_caption = slide_captions[slide_idx]
            matched_segment_texts = [seg["text"] for seg in segment_list]
            note_sections, cost = generate_note(slide_caption, matched_segment_texts)
            note_sections["Segments"] = { 
                seg["segment_key"]: {
                    "text": seg["text"],
                    "isImportant": seg["isImportant"],
                    "reason": seg["reason"],
                    "linkedConcept": seg["linkedConcept"],
                    "pageNumber": seg["pageNumber"]
                } for seg in segment_list
            }
            final_notes[slide_key] = note_sections  

        print("ê° ìŠ¬ë¼ì´ë“œë³„ í•„ê¸° ìƒì„± ì™„ë£Œ")

        # 7. íˆìŠ¤í† ë¦¬ DBì— ê²°ê³¼ ì €ì¥
        new_history = History(
            user_email=current_user.email,  
            filename=doc_file.filename,
            notes_json=final_notes,
        )
        db.add(new_history)
        db.commit()
        db.refresh(new_history)

        shutil.rmtree(temp_dir)
        return JSONResponse(content=final_notes)

    
    except Exception as e:
        if 'temp_dir' in locals() and os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
        return JSONResponse(status_code=500, content={"message": f"ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"})
