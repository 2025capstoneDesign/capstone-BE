import os
import shutil
import json
from sqlalchemy.orm import Session
from app.model.history import History
from app.api.ai import transcribe_audio
from app.service2.segment_splitter import segment_split
from app.service2.image_captioning import analyze_image, convert_pdf_to_images, image_captioning
from app.service2.segment_mapping import segment_mapping
from app.service2.summary import generate_summary
from app.service2.progress_tracker2 import update_progress, save_partial_result

def run_process_v2(
    job_id: str,
    audio_path: str,
    doc_path: str,
    skip_transcription: bool,
    original_filename: str,
    user_email: str,
    db: Session
):
    try:
        update_progress(job_id, 5, "íŒŒì¼ ì¤€ë¹„ ì™„ë£Œ")

        # 1. STT
        if skip_transcription:
            stt_dir = "data/stt_result"
            stt_files = [f for f in os.listdir(stt_dir) if f.startswith("stt_result")]
            if stt_files:
                latest_stt = max(stt_files)
                with open(os.path.join(stt_dir, latest_stt), 'r', encoding='utf-8') as f:
                    stt_result = json.load(f)
        else:
            update_progress(job_id, 10, "ì˜¤ë””ì˜¤ í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘")
            stt_result = transcribe_audio(audio_path)
        update_progress(job_id, 30, "STT ì™„ë£Œ")

        # 2. ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¦¬
        segments = segment_split(stt_data=stt_result)
        if isinstance(segments, dict) and "segments" in segments:
            segments = segments["segments"]
        update_progress(job_id, 35, "ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¦¬ ì™„ë£Œ")

        # 3. ì´ë¯¸ì§€ ìº¡ì…”ë‹ (40% â†’ 60%)
        update_progress(job_id, 40, "ì´ë¯¸ì§€ ìº¡ì…”ë‹ ì‹œì‘")

        encoded_images = convert_pdf_to_images(doc_path)
        total_slides = len(encoded_images)
        captioning = []

        for i, img_str in enumerate(encoded_images):
            image_url = f"data:image/jpeg;base64,{img_str}"

            analysis = analyze_image(image_url)

            result = {
                "slide_number": i + 1,
                "type": analysis["type"],
                "title_keywords": analysis["title_keywords"],
                "secondary_keywords": analysis["secondary_keywords"],
                "detail": analysis["detail"]
            }
            captioning.append(result)

            pct = 40 + int((i + 1) / total_slides * 20)
            update_progress(job_id, pct, f"{i + 1}/{total_slides} ìŠ¬ë¼ì´ë“œ ìº¡ì…”ë‹ ì™„ë£Œ")

        update_progress(job_id, 60, "ì´ë¯¸ì§€ ìº¡ì…”ë‹ ì™„ë£Œ")

        # 4. ì„¸ê·¸ë¨¼íŠ¸-ìŠ¬ë¼ì´ë“œ ë§¤í•‘
        mapping = segment_mapping(
            image_captioning_data=captioning,
            segment_split_data=segments
        )
        update_progress(job_id, 65, "ìŠ¬ë¼ì´ë“œ-ì„¸ê·¸ë¨¼íŠ¸ ë§¤í•‘ ì™„ë£Œ")

        # 5. ìŠ¬ë¼ì´ë“œë³„ í•„ê¸° ìƒì„± (70% â†’ 90%)
        update_progress(job_id, 70, "ìŠ¬ë¼ì´ë“œë³„ í•„ê¸° ìƒì„± ì‹œì‘")

        structured_result = {}
        filtered_mapping = {k: v for k, v in mapping.items() if k != "slide0"}
        total = len(filtered_mapping)

        for i, (slide_key, segments_data) in enumerate(filtered_mapping.items()):
            idx = int(slide_key.replace("slide", "")) - 1
            if idx >= len(captioning):
                continue

            merged_segments = "\n".join(
                seg_val.get("text", "") for seg_val in segments_data.get("Segments", {}).values()
            )

            slide_caption = captioning[idx]

            summary_data = generate_summary(slide_caption, merged_segments)

            structured_result[slide_key] = {
                "Concise Summary Notes": f"ğŸ§ Concise Summary Notes\n{summary_data['concise_summary']}",
                "Bullet Point Notes": f"âœ…Bullet Point Notes\n{summary_data['bullet_points']}",
                "Keyword Notes": f"ğŸ”‘Keyword Notes\n{summary_data['keywords']}",
                "Chart/Table Summary": f"ğŸ“ŠChart/Table Summary\n{summary_data['chart_summary']}",
                "Segments": {
                    seg_id: {
                        "text": seg_val.get("text", ""),
                        "isImportant": "false",
                        "reason": "",
                        "linkedConcept": "",
                        "pageNumber": ""
                    } for seg_id, seg_val in segments_data.get("Segments", {}).items()
                }
            }

            save_partial_result(job_id, slide_key, structured_result[slide_key])

            pct = 70 + int((i + 1) / total * 20)  # ìµœëŒ€ 90%
            update_progress(job_id, pct, f"{slide_key} í•„ê¸° ìƒì„± ì™„ë£Œ")

        # 6. DB ì €ì¥ ë° ì¢…ë£Œ
        new_history = History(
            user_email=user_email,
            filename=original_filename,
            notes_json=structured_result,
        )
        db.add(new_history)
        db.commit()

        update_progress(job_id, 100, "ì „ì²´ ì‘ì—… ì™„ë£Œ")
        shutil.rmtree(os.path.dirname(audio_path))

    except Exception as e:
        update_progress(job_id, -1, f"ì—ëŸ¬ ë°œìƒ: {str(e)}")
        if os.path.exists(os.path.dirname(audio_path)):
            shutil.rmtree(os.path.dirname(audio_path))
